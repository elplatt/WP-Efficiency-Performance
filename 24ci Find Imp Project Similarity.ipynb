{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import json\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "import scipy.stats as spstats\n",
    "import numpy as np\n",
    "import logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_file = \"data/projects-2016-10-14.json\"\n",
    "importance_file = \"archive/04b_find_importance/2017-10-03 13:54:30 14665f3/importance.utf8.tsv\"\n",
    "map_file = \"archive/07_create_article_project_map/2017-03-27 14:10:49 77c76e1/articles_projects.m\"\n",
    "similarity_file = \"similarity_mean.csv\"\n",
    "exp = logbook.Experiment(\"24ci find similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load projects\n",
    "projects = {}\n",
    "projects_by_name = {}\n",
    "with open(project_file, 'rb') as f:\n",
    "    for i, row in enumerate(f):\n",
    "        data = json.loads(row)\n",
    "        project_id = data['project_id']\n",
    "        projects[project_id] = data\n",
    "        projects[data['project_name']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load article-project map\n",
    "with open(map_file, 'rb') as f:\n",
    "    article_projects = msgpack.unpackb(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_ids = sorted(projects.keys())                \n",
    "project_important = dict((project_id, set()) for project_id in project_ids)\n",
    "skipped_projects = set()\n",
    "with open(importance_file, \"rb\") as f:\n",
    "    for row in f:\n",
    "        row = row.decode('utf-8')\n",
    "        title, unique, page_id, importance = row.strip().split(u'\\t')\n",
    "        if importance == 'Top' or importance == 'High':\n",
    "            try:\n",
    "                project_id = projects_by_name[unique][\"project_id\"]\n",
    "                project_important[project_id].add(int(page_id))\n",
    "            except KeyError:\n",
    "                skipped_projects.add(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_articles = {}\n",
    "for article_id, project_times in article_projects.iteritems():\n",
    "    for project_id in project_times.keys():\n",
    "        if article_id in project_important[project_id]:\n",
    "            try:\n",
    "                project_articles[project_id].add(article_id)\n",
    "            except KeyError:\n",
    "                project_articles[project_id] = set([article_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log = exp.get_logger()\n",
    "similarity = {}\n",
    "# Exclude empty projects\n",
    "project_ids = project_articles.keys()\n",
    "with open(exp.get_filename(\"similarity.csv\"), \"wb\") as out:\n",
    "    out.write(\"low_id,high_id,jaccard\\n\")\n",
    "    for i, low in enumerate(project_ids):\n",
    "        log.info(\"low: %d\", low)\n",
    "        for high in project_ids[i+1:]:\n",
    "            low_articles = set(project_articles[low])\n",
    "            high_articles = set(project_articles[high])\n",
    "            union = low_articles | high_articles\n",
    "            intersection = low_articles & high_articles\n",
    "            jaccard = float(len(intersection)) / float(len(union))\n",
    "            similarity[(low, high)] = jaccard\n",
    "            similarity[(high, low)] = jaccard\n",
    "            out.write(\"%d,%d,%s\\n\" % (low, high, repr(jaccard)))\n",
    "        out.flush()\n",
    "log.info(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_ids = projects.keys()\n",
    "col_project_id = []\n",
    "col_similarity_mean = []\n",
    "col_title = []\n",
    "for a in project_ids:\n",
    "    psim = []\n",
    "    for b in project_ids:\n",
    "        try:\n",
    "            psim.append(similarity[(int(a), int(b))])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if len(psim) > 0:\n",
    "        col_project_id.append(a)\n",
    "        col_similarity_mean.append(np.mean(psim))\n",
    "        col_title.append(projects[int(a)][\"project_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"project_id\": col_project_id,\n",
    "    \"similarity_mean\": col_similarity_mean\n",
    "}).set_index(\"project_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = exp.get_filename(similarity_file)\n",
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
