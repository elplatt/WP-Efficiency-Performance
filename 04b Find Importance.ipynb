{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from IPython.display import clear_output\n",
    "from lxml import html\n",
    "import requests\n",
    "import sys\n",
    "from urlparse import parse_qs, urlparse\n",
    "import logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensure_unicode(s):\n",
    "    if isinstance(s, unicode):\n",
    "        return s\n",
    "    else:\n",
    "        return s.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp = logbook.Experiment(\"04b_find_importance\")\n",
    "log = exp.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = requests.get(\"https://tools.wmflabs.org/enwp10/cgi-bin/pindex.fcgi?sec=[All]\")\n",
    "parser = html.HTMLParser(encoding='utf-8')\n",
    "tree = html.document_fromstring(page.content, parser=parser)\n",
    "rows = tree.xpath(\"//table[@class='wikitable']//tr\")\n",
    "\n",
    "log.info(\"Parsing projects\")\n",
    "projects = []\n",
    "for i, row in enumerate(rows):\n",
    "    cells = row.xpath(\"td\")\n",
    "    if len(cells) < 3:\n",
    "        continue\n",
    "    # Parse project title\n",
    "    if (len(cells[0][0]) == 0):\n",
    "        title = ensure_unicode(cells[0][0].text)\n",
    "        project_title = title\n",
    "        project_unique = title\n",
    "    else:\n",
    "        title = ensure_unicode(cells[0][0][0].text)\n",
    "        try:\n",
    "            url = cells[0][0][0].attrib['href']\n",
    "            query = urlparse(url).query\n",
    "            unique = parse_qs(query)['title'][0].decode('utf8')\n",
    "            project_title = title\n",
    "            project_unique = unique\n",
    "        except KeyError:\n",
    "            # No title\n",
    "            project_title = title\n",
    "            project_unique = title\n",
    "    # Parse list url\n",
    "    project_list = cells[2].xpath(\"a[1]\")[0].attrib['href']\n",
    "    projects.append( (project_title, project_unique, project_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse articles\n",
    "log.info(\"Parsing project articles\")\n",
    "try:\n",
    "    with open(exp.get_filename(\"importance_url.utf8.tsv\"), \"wb\") as out:\n",
    "        out.write(\"proj_title, proj_unique, page_url, importance\\n\")\n",
    "        articles = [] # [project_title, project_unique, article_url, importance]\n",
    "        for project in projects:\n",
    "            # Get list of articles in project\n",
    "            query = urlparse(project[2]).query\n",
    "            project_query = parse_qs(query)['project'][0]\n",
    "            url = \"https://tools.wmflabs.org/enwp10/cgi-bin/list2.fcgi?run=yes&projecta=%s&namespace=&pagename=&quality=&importance=&score=&limit=250&offset=1&sorta=Importance&sortb=Quality\" % project_query\n",
    "            page = requests.get(url)\n",
    "            parser = html.HTMLParser(encoding='utf-8')\n",
    "            tree = html.document_fromstring(page.content, parser=parser)\n",
    "            rows = tree.xpath(\"//table[@class='wikitable']//tr\")\n",
    "            if len(rows) == 0:\n",
    "                print \"No rows in \" + project[0]\n",
    "                continue\n",
    "            for row in rows:\n",
    "                cells = row.xpath(\"td\")\n",
    "                article_data = [project[0], project[1]]\n",
    "                try:\n",
    "                    article_data.append(cells[1][0].attrib['href'])\n",
    "                    article_data.append(cells[2][0].text)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                out.write(\"\\t\".join([\n",
    "                    article_data[0].encode('utf8'),\n",
    "                    article_data[1].encode('utf8'),\n",
    "                    article_data[2].encode('utf8'),\n",
    "                    article_data[3].encode('utf8')\n",
    "                ]) + \"\\n\")\n",
    "                out.flush()\n",
    "                articles.append(article_data)\n",
    "                clear_output()\n",
    "except:\n",
    "    log.error(sys.exc_info())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace url with page id\n",
    "try:\n",
    "    for i, article in enumerate(articles):\n",
    "        query = urlparse(article[2]).query\n",
    "        article_title = parse_qs(query)['title'][0]\n",
    "        info_url = \"https://en.wikipedia.org/w/index.php?title=%s&action=info\" % article_title\n",
    "        page = requests.get(info_url)\n",
    "        parser = html.HTMLParser(encoding='utf-8')\n",
    "        tree = html.document_fromstring(page.content, parser=parser)\n",
    "        cell = tree.xpath(\"//tr[@id='mw-pageinfo-article-id']//td\")[1]\n",
    "        page_id = int(cell.text.strip())\n",
    "        articles[i][2] = page_id\n",
    "        clear_output()\n",
    "except:\n",
    "    log.error(sys.exc_info())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(exp.get_filename(\"importance.utf8.tsv\"), \"wb\") as out:\n",
    "    out.write(\"proj_title, proj_unique, page_id, importance\\n\")\n",
    "    for article in articles:\n",
    "        out.write(\"\\t\".join([\n",
    "            article[0].encode('utf8'),\n",
    "            article[1].encode('utf8'),\n",
    "            str(article[2]),\n",
    "            article[3].encode('utf8')\n",
    "        ]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
