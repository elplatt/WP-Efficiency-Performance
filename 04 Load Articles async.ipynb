{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import requests\n",
      "import sys\n",
      "from threading import Thread\n",
      "import time\n",
      "from Queue import Empty, Queue\n",
      "from IPython.display import clear_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlalchemy\n",
      "from sqlalchemy.exc import IntegrityError\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "import database\n",
      "from database.schema import article_project"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "projfile = 'data/articles-projects.json'\n",
      "logfile = 'data/04-load-articles.log'\n",
      "wiki_api = 'https://en.wikipedia.org/w/api.php'\n",
      "batch_size = 50\n",
      "num_workers = 25"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_title_helper(i, project_id, titles, c):\n",
      "    query = article_project.insert()\n",
      "    #print \"%d Acquired data\" % i\n",
      "    #sys.stdout.flush()\n",
      "    payload = {'action': 'query', 'format': 'json', 'titles': '|'.join(titles) }\n",
      "    r = requests.get(wiki_api, params=payload)\n",
      "    #print \"%d Received response\" % i\n",
      "    #sys.stdout.flush()\n",
      "    data = r.json()\n",
      "    #print \"Parsed successfully.\"\n",
      "    #sys.stdout.flush()\n",
      "    values = []\n",
      "    for article_id in data['query']['pages'].iterkeys():\n",
      "        if int(article_id) > 0:\n",
      "            values.append({\"article_id\":article_id, \"project_id\":project_id})\n",
      "    #print \"Executing SQL...\"\n",
      "    #sys.stdout.flush()\n",
      "    sql = c.execute(query.values(values))\n",
      "    #print \"Done.\"\n",
      "    #sys.stdout.flush()\n",
      "\n",
      "def process_titles(i, q, conn):\n",
      "    '''Process titles until queue is empty.'''\n",
      "    while True:\n",
      "        try:\n",
      "            #print \"Waiting for task.\"\n",
      "            project_id, titles = q.get(False)\n",
      "            #print \"Task received.\"\n",
      "        except Empty:\n",
      "            #print \"Queue emtpy, breaking.\"\n",
      "            return\n",
      "        process_title_helper(i, project_id, titles, conn)\n",
      "        q.task_done()\n",
      "        #print \"Sleeping\"\n",
      "        #sys.stdout.flush()\n",
      "        time.sleep(1)\n",
      "        #print \"Woke up\"\n",
      "        #sys.stdout.flush()\n",
      "        \n",
      "def process_titles_daemon(i, q, conn):\n",
      "    '''process titles and block when no more are available.'''\n",
      "    global complete\n",
      "    print \"%d waiting...\" % i\n",
      "    while True:\n",
      "        try:\n",
      "            if complete:\n",
      "                conn.close()\n",
      "                return\n",
      "            process_titles(i, q, conn)\n",
      "            time.sleep(0.1)\n",
      "        except:\n",
      "            print \"Exception in proces_titles_daemon()\"\n",
      "            print sys.exc_info()\n",
      "            sys.stdout.flush()\n",
      "            conn.close()\n",
      "            return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = {}\n",
      "proj_map = {}\n",
      "conn = []\n",
      "workers = []\n",
      "complete = False\n",
      "start = time.time()\n",
      "if num_workers == 0:\n",
      "    c = database.engine.connect()\n",
      "count = 0;\n",
      "q = Queue()\n",
      "try:\n",
      "    print \"Creating workers\"\n",
      "    for i in range(num_workers):\n",
      "        print \"Creating %d\" % i\n",
      "        conn.append(database.engine.connect())\n",
      "        worker = Thread(target=process_titles_daemon, args=(i, q, conn[i]))\n",
      "        worker.setDaemon(True)\n",
      "        worker.start()\n",
      "        workers.append(worker)\n",
      "    print \"Workers created.\"\n",
      "except:\n",
      "    print sys.exc_info()\n",
      "    sys.stdout.flush()\n",
      "    complete = True\n",
      "    sys.exit()\n",
      "sys.stdout.flush()\n",
      "try:\n",
      "    print \"Sending API requests.\"\n",
      "    with open(projfile, 'rb') as f:\n",
      "        for i, row in enumerate(f):\n",
      "            project = json.loads(row);\n",
      "            titles = project['articles']\n",
      "            remaining = -1\n",
      "            if i > 0:\n",
      "                remaining = (time.time() - start) / float(i) * (2038.0 - i) / 60.0 / 60.0\n",
      "            print \"p:%d a:%d q:%d w:%d r:%f Starting: %s\" % (\n",
      "                i+1,\n",
      "                count,\n",
      "                q.qsize(),\n",
      "                len([1 for t in workers if t.is_alive()]),\n",
      "                remaining,\n",
      "                project['project_name'])\n",
      "            while len(titles) > 0:\n",
      "                fetch = titles[0:batch_size]\n",
      "                titles = titles[batch_size:]\n",
      "                count += len(fetch)\n",
      "                q.put((project['project_id'],fetch))\n",
      "                if num_workers == 0:\n",
      "                    process_titles(0, q, c)\n",
      "                sys.stdout.write(\".\")\n",
      "                sys.stdout.flush()\n",
      "                if q.qsize() > num_workers:\n",
      "                    time.sleep(1)\n",
      "            sys.stdout.write(\"\\n\");\n",
      "            if q.qsize() > 1000 and (True in [t.is_alive() for t in workers]):\n",
      "                print \"Waiting for queue size to decrease\"\n",
      "                sys.stdout.flush()\n",
      "                time.sleep(10)\n",
      "    print \"*** Finished sending requests ***\"\n",
      "    print \"*** Waiting for processing to complete ***\"\n",
      "    sys.stdout.flush()\n",
      "    while q.qsize() > 0 and (True in [t.is_alive() for t in workers]):\n",
      "        time.sleep(1)\n",
      "    print \"*** Finished parsing requests ***\"\n",
      "    sys.stdout.flush()\n",
      "except KeyboardInterrupt:\n",
      "    pass\n",
      "finally:\n",
      "    complete = True\n",
      "    with q.mutex:\n",
      "        q.queue.clear()\n",
      "    time.sleep(1)\n",
      "    for c in conn:\n",
      "        try:\n",
      "            c.close()\n",
      "        except AttributeError:\n",
      "            pass\n",
      "    complete = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}