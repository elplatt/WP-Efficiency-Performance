{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import calendar\n",
      "import csv\n",
      "import datetime\n",
      "import dateutil.parser\n",
      "import json\n",
      "import sys\n",
      "import time\n",
      "import sqlalchemy\n",
      "from sqlalchemy.exc import IntegrityError\n",
      "from sqlalchemy.orm import sessionmaker"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_file = \"data/articles-projects.json\"\n",
      "history_file = \"data/final_history_output-modified.csv\"\n",
      "log_file = \"data/06_load_history.log\"\n",
      "batch_size = 100000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import database\n",
      "from database.schema import (\n",
      "    article_project,\n",
      "    article_project_names,\n",
      "    revision_table\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(history_file, 'rU') as f:\n",
      "    r = csv.reader(f)\n",
      "    print len(r.next())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "revision_shards = {}\n",
      "projects = {}\n",
      "projects_by_name = {}\n",
      "with open(project_file, 'rb') as f:\n",
      "    for i, row in enumerate(f):\n",
      "        data = json.loads(row)\n",
      "        project_id = data['project_id']\n",
      "        projects[project_id] = data\n",
      "        projects[project_id]['articles'] = set(projects[project_id]['articles'])\n",
      "        projects_by_name[data[\"project_name\"]] = project_id\n",
      "        t = revision_table(project_id)\n",
      "        revision_shards[project_id] = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Session = sessionmaker()\n",
      "Session.configure(bind=database.engine)\n",
      "session = Session()\n",
      "time_db = 0.0\n",
      "time_search = 0.0\n",
      "time_io = 0.0\n",
      "time_parse = 0.0\n",
      "time_orm = 0.0\n",
      "with open(log_file, 'wb') as log:\n",
      "    try:\n",
      "        for project_id in projects.iterkeys():\n",
      "            last = -1\n",
      "            project_name = projects[project_id]['project_name']\n",
      "            project_table = revision_shards[project_id]\n",
      "            #print('Beginning project %d: %s\\n' % (project_id, project_name))\n",
      "            #sys.stdout.flush()\n",
      "            log.write(\"Beginning project\\t%d\\t%s\\n\" % (project_id, project_name))\n",
      "            log.write(\"Performance\\tdb:%f\\tsearch:%f\\tio:%f\\tparse:%f\\torm:%f\\n\" % (\n",
      "                            time_db, time_search, time_io, time_parse, time_orm))\n",
      "            log.flush()\n",
      "            articles_names = set(projects[project_id]['articles'])\n",
      "            article_ids = set()\n",
      "            #print(\"Loading article ids\")\n",
      "            #sys.stdout.flush()\n",
      "            start = time.time()\n",
      "            for article_id in session.query(article_project.c.article_id) \\\n",
      "                    .filter(article_project.c.project_id == project_id).all():\n",
      "                article_ids.add(article_id[0])\n",
      "            #print \"Finished loading %d ids in %f seconds\" % (len(article_ids), time.time() - start)\n",
      "            to_insert = []\n",
      "            #print(\"Opening history file\");\n",
      "            #sys.stdout.flush()\n",
      "            start = time.time()\n",
      "            io_start = time.time()\n",
      "            with open(history_file, 'rb') as f:\n",
      "                skipped = []\n",
      "                reader = csv.reader(f)\n",
      "                for i, row in enumerate(reader):\n",
      "                    time_io += time.time() - io_start\n",
      "                    last = i\n",
      "                    #if i % 100000 == 0:\n",
      "                        #log.write(\"Rows processed\\t%d\\t%f\\n\" % (i, time.time() - start))\n",
      "                        #print \"%d rows processed in %f seconds\" % (i, time.time() - start)\n",
      "                        #print \"db:%f\\tsearch:%f\\tio:%f\\tparse:%f\\torm:%f\" % (\n",
      "                        #    time_db, time_search, time_io, time_parse, time_orm)\n",
      "                        #sys.stdout.flush()\n",
      "                        #log.flush()\n",
      "                    try:\n",
      "                        (article_name\n",
      "                         , article_namespace\n",
      "                         , article_id\n",
      "                         , redirect\n",
      "                         , revision_num\n",
      "                         , revision_id\n",
      "                         , timestamp\n",
      "                         , contributor_name\n",
      "                         , contributor_id\n",
      "                         , minor\n",
      "                         , comment\n",
      "                         , bytes\n",
      "                         , bytes_diff\n",
      "                         , deleted) = row\n",
      "                        if article_id is not '' and article_id is not '-1':\n",
      "                            search_start = time.time()\n",
      "                            in_project = int(article_id.strip()) in article_ids\n",
      "                            time_search += time.time() - search_start\n",
      "                            if in_project:\n",
      "                                parse_start = time.time()\n",
      "                                ts = dateutil.parser.parse(timestamp)\n",
      "                                ts = datetime.datetime.fromtimestamp(calendar.timegm(ts.timetuple()))\n",
      "                                if contributor_id == '':\n",
      "                                    contributor_id = 0\n",
      "                                if minor == '1':\n",
      "                                    minor = True\n",
      "                                else:\n",
      "                                    minor = False\n",
      "                                time_parse += time.time() - parse_start\n",
      "                                orm_start = time.time()\n",
      "                                to_insert.append(\n",
      "                                    project_table(\n",
      "                                        article_name = article_name\n",
      "                                         , article_id = article_id\n",
      "                                         , redirect = redirect\n",
      "                                         , revision_num = revision_num\n",
      "                                         , revision_id = revision_id\n",
      "                                         , timestamp = ts\n",
      "                                         , contributor_id = contributor_id\n",
      "                                         , minor = minor\n",
      "                                         , comment = comment\n",
      "                                         , diff_bytes = bytes_diff\n",
      "                                    )\n",
      "                                )\n",
      "                                time_orm += time.time() - orm_start\n",
      "                        else:\n",
      "                            search_start = time.time()\n",
      "                            in_project = article_name in article_names\n",
      "                            time_search += time.time() - search_start\n",
      "                            if in_project:\n",
      "                                parse_start = time.time()\n",
      "                                ts = dateutil.parser.parse(timestamp)\n",
      "                                ts = datetime.datetime.fromtimestamp(calendar.timegm(ts.timetuple()))\n",
      "                                if contributor_id == '':\n",
      "                                    contributor_id = 0\n",
      "                                if minor == '1':\n",
      "                                    minor = True\n",
      "                                else:\n",
      "                                    minor = False\n",
      "                                time_parse += time.time() - parse_start\n",
      "                                orm_start = time.time()\n",
      "                                to_insert.append(\n",
      "                                    project_table(\n",
      "                                        article_name = article_name\n",
      "                                         , article_id = -1\n",
      "                                         , redirect = redirect\n",
      "                                         , revision_num = revision_num\n",
      "                                         , revision_id = revision_id\n",
      "                                         , timestamp = ts\n",
      "                                         , contributor_id = contributor_id\n",
      "                                         , minor = minor\n",
      "                                         , comment = comment\n",
      "                                         , diff_bytes = bytes_diff\n",
      "                                    )\n",
      "                                )\n",
      "                                orm_time += time.time() - orm_start\n",
      "                        if len(to_insert) >= batch_size:\n",
      "                            #print \"Commiting %d rows\" % len(to_insert)\n",
      "                            db_start = time.time()\n",
      "                            session.add_all(to_insert)\n",
      "                            session.commit()\n",
      "                            to_insert = []\n",
      "                            time_db += time.time() - db_start\n",
      "                        io_start = time.time()\n",
      "                    except ValueError:\n",
      "                        #print(\"Skipped row\\t%d\\t%s\\n\" % (i, sys.exc_info()))\n",
      "                        log.write(\"Skipped row\\t%d\\t%s\\n\" % (i, sys.exc_info()))\n",
      "                        log.flush()\n",
      "                        io_start = time.time()\n",
      "                        continue\n",
      "                print \"Commiting %d rows\" % len(to_insert)\n",
      "                db_start = time.time()\n",
      "                session.add_all(to_insert)\n",
      "                session.commit()\n",
      "                time_db += time.time() - db_start\n",
      "                to_insert = []\n",
      "                time.sleep(0.1)\n",
      "    except:\n",
      "        log.write(\"Exception on row\\t%d\\t%s\\n\" % (last, sys.exc_info()))\n",
      "        log.flush()\n",
      "        session.close()\n",
      "        raise\n",
      "session.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}