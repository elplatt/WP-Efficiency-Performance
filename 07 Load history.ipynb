{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import calendar\n",
      "import csv\n",
      "import datetime\n",
      "import dateutil.parser\n",
      "import json\n",
      "import logging\n",
      "import sys\n",
      "import time\n",
      "import sqlalchemy\n",
      "from sqlalchemy.exc import IntegrityError\n",
      "from sqlalchemy.orm import sessionmaker"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_file = \"data/articles-projects.json\"\n",
      "history_file = \"data/history_sample.csv\"\n",
      "log_file = \"output/07_load_history.log\"\n",
      "batch_size = 1000\n",
      "between_sleep_sec = 5.0\n",
      "sleep_sec = 0.1\n",
      "history_columns = [\n",
      "    \"article_name\"\n",
      "     , \"article_namespace\"\n",
      "     , \"article_id\"\n",
      "     , \"redirect\"\n",
      "     , \"revision_num\"\n",
      "     , \"revision_id\"\n",
      "     , \"timestamp\"\n",
      "     , \"contributor_name\"\n",
      "     , \"contributor_id\"\n",
      "     , \"minor\"\n",
      "     , \"comment\"\n",
      "     , \"length_bytes\"\n",
      "     , \"diff_bytes\"\n",
      "     , \"deleted\"\n",
      "]\n",
      "exclude_columns = [\"contributor_name\", \"article_namespace\", \"deleted\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import database\n",
      "from database.schema import (\n",
      "    article_project,\n",
      "    article_project_names,\n",
      "    revision_table\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class HistoryIndexer(object):\n",
      "    \n",
      "    def __init__(self, project_file, history_file, Session, log):\n",
      "        log.debug(\"Creating HistoryIndexer\")\n",
      "        self.Session = Session\n",
      "        self.history_file = history_file\n",
      "        self.project_file = project_file\n",
      "        self.log = log\n",
      "        self.to_insert = []\n",
      "        self.profile = { \"db\":0, \"search\":0, \"io\":0, \"parse\":0, \"orm\":0 }\n",
      "        self.article_ids = None\n",
      "        self.project_tables = {}\n",
      "        self.project_table = None\n",
      "        self.timestamps = {}\n",
      "        self.last_sleep = time.time()\n",
      "        \n",
      "    def load_projects(self):\n",
      "        self.log.debug(\"load_projects()\")\n",
      "        self.projects = {}\n",
      "        self.projects_by_name = {}\n",
      "        with open(self.project_file, 'rb') as f:\n",
      "            for i, row in enumerate(f):\n",
      "                data = json.loads(row)\n",
      "                project_id = data['project_id']\n",
      "                self.projects[project_id] = data\n",
      "                self.projects[project_id]['articles'] = set(self.projects[project_id]['articles'])\n",
      "                self.projects_by_name[data[\"project_name\"]] = project_id\n",
      "        \n",
      "    def get_article_ids(self, project_id):\n",
      "        try:\n",
      "            return self.projects[project_id][\"article_ids\"]\n",
      "        except KeyError:\n",
      "            pass\n",
      "        self.profile[\"db_start\"] = time.time()\n",
      "        # Loaded as list to keep db benchmarks separate from set creation benchmarks\n",
      "        article_id_list = []\n",
      "        for article_id in self.session.query(article_project.c.article_id) \\\n",
      "                .filter(article_project.c.project_id == project_id).all():\n",
      "            article_id_list.append(article_id[0])\n",
      "        self.profile[\"db\"] += time.time() - self.profile[\"db_start\"]\n",
      "        self.projects[project_id][\"article_ids\"] = set(article_id_list)\n",
      "        return self.projects[project_id][\"article_ids\"]\n",
      "        \n",
      "    def get_project_table(self, project_id):\n",
      "        self.log.debug(\"get_project_table()\")\n",
      "        try:\n",
      "            return self.project_tables[project_id]\n",
      "        except KeyError:\n",
      "            t = revision_table(project_id)\n",
      "            self.project_tables[project_id] = t\n",
      "            return t\n",
      "\n",
      "    def parse_history_row(self, row):\n",
      "        datum = {}\n",
      "        for i, name in enumerate(history_columns):\n",
      "            if name not in exclude_columns:\n",
      "                datum[name] = row[i]\n",
      "        return datum\n",
      "    \n",
      "    def get_timestamp(self, s):\n",
      "        try:\n",
      "            return self.timestamps[s]\n",
      "        except KeyError:\n",
      "            pass\n",
      "        ts = dateutil.parser.parse(s)\n",
      "        dt = datetime.datetime.fromtimestamp(calendar.timegm(ts.timetuple()))\n",
      "        self.timestamps[s] = dt\n",
      "        return dt\n",
      "    \n",
      "    def index_article(self, datum, project_table):\n",
      "        # Check if the article is in the project\n",
      "        self.profile[\"search_start\"] = time.time()\n",
      "        is_in_project = int(datum[\"article_id\"].strip()) in self.article_ids\n",
      "        self.profile[\"search\"] += time.time() - self.profile[\"search_start\"]\n",
      "        if not is_in_project:\n",
      "            return\n",
      "        # Parse the timestamp\n",
      "        datum[\"timestamp\"] = self.get_timestamp(datum[\"timestamp\"])\n",
      "        # Index the article        \n",
      "        self.profile[\"parse_start\"] = time.time()\n",
      "        self.to_insert.append(project_table(**datum))\n",
      "        self.profile[\"parse\"] += time.time() - self.profile[\"parse_start\"]\n",
      "        \n",
      "    def index_deleted_article(self, datum, project_table):\n",
      "        # Check if the article is in the project\n",
      "        # Deleted articles don't have their ids listed, search by name\n",
      "        self.profile[\"search_start\"] = time.time()\n",
      "        is_in_project = article_name in self.article_names\n",
      "        self.profile[\"search\"] += time.time() - self.profile[\"search_start\"]\n",
      "        if not is_in_project:\n",
      "            return\n",
      "        self.profile[\"parse_start\"] = time.time()\n",
      "        self.to_insert.append(project_table(**datum))\n",
      "        self.profile[\"parse\"] += time.time() - self.profile[\"parse_start\"]\n",
      "    \n",
      "    def index_project(self, project_id, data):\n",
      "        self.log.debug(\"index_project()\")\n",
      "        session = self.session\n",
      "        log = self.log\n",
      "        profile = self.profile\n",
      "        project_name = self.projects[project_id]['project_name']\n",
      "        project_table = self.get_project_table(project_id)\n",
      "        self.timestamps = {}\n",
      "        \n",
      "        log.info(\"Beginning: %d\\tOffset: %d\" % (project_id, self.rows_completed))\n",
      "\n",
      "        # Get list of article ids and names in project\n",
      "        self.article_ids = self.get_article_ids(project_id)\n",
      "        self.articles_names = self.projects[project_id]['articles']\n",
      "\n",
      "        self.to_insert = []\n",
      "        for i, row in enumerate(data):\n",
      "            last = i\n",
      "            try:\n",
      "                self.profile[\"parse_start\"] = time.time()\n",
      "                datum = self.parse_history_row(row)\n",
      "                self.profile[\"parse\"] += time.time() - self.profile[\"parse_start\"]\n",
      "            except IndexError:\n",
      "                log.warning(\"Skipped row\\t%d\\t%s\" % (row_offset + i, sys.exc_info()))\n",
      "                continue\n",
      "            if datum[\"article_id\"] is not '' and datum[\"article_id\"] is not '-1':\n",
      "                self.index_article(datum, project_table)\n",
      "            else:\n",
      "                self.index_deleted_article(datum, project_table)\n",
      "        if len(self.to_insert) > 0:\n",
      "            log.debug(\"Commiting %d rows\" % len(self.to_insert))\n",
      "            self.profile[\"db_start\"] = time.time()\n",
      "            session.add_all(self.to_insert)\n",
      "            session.commit()\n",
      "            self.profile[\"db\"] += time.time() - self.profile[\"db_start\"]\n",
      "            self.to_insert = []\n",
      "            elapsed = time.time() - self.begin\n",
      "            self.log.info(\"Profile\\tio:%f\\tsearch:%f\\tdb:%f\" % (\n",
      "                self.profile[\"io\"], self.profile[\"search\"], self.profile[\"db\"]))\n",
      "        t = time.time()\n",
      "        if t - self.last_sleep > between_sleep_sec:\n",
      "            time.sleep(sleep_sec)\n",
      "            self.last_sleep = t\n",
      "    \n",
      "    def index_all(self):\n",
      "        self.log.debug(\"index_all()\")\n",
      "        self.load_projects()\n",
      "        self.rows_completed = 0\n",
      "        self.begin = time.time()\n",
      "        try:\n",
      "            self.session = Session()\n",
      "            with open(self.history_file, 'rb') as f:\n",
      "                # Iterate through history batch_size lines at a time\n",
      "                reader = csv.reader(f)\n",
      "                try:\n",
      "                    while True:\n",
      "                        data = []\n",
      "                        self.log.info(\"Reading batch\\t%d\\n\" % self.rows_completed)\n",
      "                        self.profile[\"io_start\"] = time.time()\n",
      "                        for i in range(batch_size):\n",
      "                            data.append(reader.next())\n",
      "                        self.profile[\"io\"] += time.time() - self.profile[\"io_start\"]\n",
      "                        # Process the batch once for each project\n",
      "                        for project_id in self.projects.iterkeys():\n",
      "                            self.index_project(project_id, data)\n",
      "                        self.rows_completed += len(data)\n",
      "                        if self.rows_completed > 0:\n",
      "                            elapsed = time.time() - self.begin\n",
      "                            self.log.info(\"Batch complete\\t%d\\t%f\\t%f\\n\" % (\n",
      "                                self.rows_completed,\n",
      "                                elapsed,\n",
      "                                elapsed / float(self.rows_completed)))\n",
      "                except StopIteration:\n",
      "                    # Finish processing the last batch of data\n",
      "                    self.profile[\"io\"] += time.time() - self.profile[\"io_start\"]\n",
      "                    for project_id in self.projects.iterkeys():\n",
      "                        self.index_project(project_id, data)\n",
      "                    self.rows_completed += len(data)\n",
      "        except:\n",
      "            self.session.close()\n",
      "            raise\n",
      "        finally:\n",
      "            self.session.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log = logging.getLogger(\"wp-efficiency-performance:load-history\")\n",
      "log.propagate = False\n",
      "log.handlers = []\n",
      "handler = logging.FileHandler(log_file, \"w\")\n",
      "log.addHandler(handler)\n",
      "log.setLevel(logging.INFO)\n",
      "\n",
      "Session = sessionmaker()\n",
      "Session.configure(bind=database.engine)\n",
      "\n",
      "hi = HistoryIndexer(project_file, history_file, Session, log)\n",
      "hi.index_all()\n",
      "handler.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}