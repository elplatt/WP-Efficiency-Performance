{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import calendar\n",
      "import csv\n",
      "import datetime\n",
      "import dateutil.parser\n",
      "from collections import deque\n",
      "import json\n",
      "from pickle import Unpickler\n",
      "import sys\n",
      "import time\n",
      "import sqlalchemy\n",
      "from sqlalchemy.exc import IntegrityError\n",
      "from sqlalchemy.orm import sessionmaker"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_file = \"data/articles-projects.json\"\n",
      "history_file = \"data/history.p\"\n",
      "log_file = \"data/07_load_history.log\"\n",
      "start_on_project = 73\n",
      "batch_size = 10000\n",
      "input_buffer_bytes = (1024 * 1024)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import database\n",
      "from database.schema import (\n",
      "    article_project,\n",
      "    article_project_names,\n",
      "    revision_table\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FlushStream(object):\n",
      "    def __init__(self, f=sys.stdout):\n",
      "        self.f = f\n",
      "    def write(self, s):\n",
      "        self.f.write(s)\n",
      "        self.f.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "projects = {}\n",
      "projects_by_name = {}\n",
      "with open(project_file, 'rb') as f:\n",
      "    for i, row in enumerate(f):\n",
      "        data = json.loads(row)\n",
      "        project_id = data['project_id']\n",
      "        projects[project_id] = data\n",
      "        projects[project_id]['articles'] = set(projects[project_id]['articles'])\n",
      "        projects_by_name[data[\"project_name\"]] = project_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Session = sessionmaker()\n",
      "Session.configure(bind=database.engine)\n",
      "session = Session()\n",
      "time_db = 0.0\n",
      "time_search = 0.0\n",
      "time_io = 0.0\n",
      "time_parse = 0.0\n",
      "time_orm = 0.0\n",
      "row_count = 0\n",
      "last = -1\n",
      "with open(log_file, 'wb') as log:\n",
      "    #output = FlushStream()\n",
      "    output = FlushStream(log)\n",
      "    try:\n",
      "        start = time.time()\n",
      "        for project_id in projects.iterkeys():\n",
      "            if project_id < start_on_project:\n",
      "                continue\n",
      "            project_name = projects[project_id]['project_name']\n",
      "            output.write(\"Beginning project\\t%d\\t%s\\n\" % (project_id, project_name))\n",
      "            sofar = time.time() - start\n",
      "            output.write(\"Acquiring revision table\")\n",
      "            project_table = revision_table(project_id)\n",
      "            articles_names = set(projects[project_id]['articles'])\n",
      "            article_ids = set()\n",
      "            output.write(\"Loading article ids\\n\")\n",
      "            start = time.time()\n",
      "            for article_id in session.query(article_project.c.article_id) \\\n",
      "                    .filter(article_project.c.project_id == project_id).all():\n",
      "                article_ids.add(article_id[0])\n",
      "            output.write(\"Finished loading %d ids in %f seconds\\n\" % (\n",
      "                len(article_ids), time.time() - start))\n",
      "            to_insert = []\n",
      "            output.write(\"Opening history file\\n\")\n",
      "            start = time.time()\n",
      "            io_start = time.time()\n",
      "            f = open(history_file, 'rb', input_buffer_bytes)\n",
      "            p = Unpickler(f)\n",
      "            skipped = []\n",
      "            last = -1\n",
      "            next_i = 0\n",
      "            while True:\n",
      "                try:\n",
      "                    row = p.load()\n",
      "                    time_io += time.time() - io_start\n",
      "                    i = next_i\n",
      "                    next_i += 1\n",
      "                    last = i\n",
      "                    if i % 10000 == 0:\n",
      "                        if row_count > 0:\n",
      "                            sofar = time.time() - start\n",
      "                            output.write(\"Rows processed\\t%d\\t%f\\t%f\\n\" % (\n",
      "                                row_count, sofar, sofar/float(row_count)))\n",
      "                            output.write(\"Performance\\tdb:%f\\tsearch:%f\\tio:%f\\tparse:%f\\torm:%f\\n\" % (\n",
      "                                time_db, time_search, time_io, time_parse, time_orm))\n",
      "                        time.sleep(0.1)\n",
      "                    row_count += 1\n",
      "                    io_start = time.time()\n",
      "                    try:\n",
      "                        (article_name\n",
      "                         , article_namespace\n",
      "                         , article_id\n",
      "                         , redirect\n",
      "                         , revision_num\n",
      "                         , revision_id\n",
      "                         , timestamp\n",
      "                         , contributor_name\n",
      "                         , contributor_id\n",
      "                         , minor\n",
      "                         , comment\n",
      "                         , bytes\n",
      "                         , bytes_diff) = row\n",
      "    #                         , deleted) = row\n",
      "                        if article_id is not '' and article_id is not '-1':\n",
      "                            search_start = time.time()\n",
      "                            in_project = int(article_id.strip()) in article_ids\n",
      "                            time_search += time.time() - search_start\n",
      "                            if in_project:\n",
      "                                parse_start = time.time()\n",
      "                                ts = dateutil.parser.parse(timestamp)\n",
      "                                ts = datetime.datetime.fromtimestamp(calendar.timegm(ts.timetuple()))\n",
      "                                if contributor_id == '':\n",
      "                                    contributor_id = 0\n",
      "                                if minor == '1':\n",
      "                                    minor = True\n",
      "                                else:\n",
      "                                    minor = False\n",
      "                                time_parse += time.time() - parse_start\n",
      "                                orm_start = time.time()\n",
      "                                to_insert.append(\n",
      "                                    project_table(\n",
      "                                        article_name = article_name\n",
      "                                         , article_id = article_id\n",
      "                                         , redirect = redirect\n",
      "                                         , revision_num = revision_num\n",
      "                                         , revision_id = revision_id\n",
      "                                         , timestamp = ts\n",
      "                                         , contributor_id = contributor_id\n",
      "                                         , minor = minor\n",
      "                                         , comment = comment\n",
      "                                         , diff_bytes = bytes_diff\n",
      "                                    )\n",
      "                                )\n",
      "                                time_orm += time.time() - orm_start\n",
      "                        else:\n",
      "                            search_start = time.time()\n",
      "                            in_project = article_name in article_names\n",
      "                            time_search += time.time() - search_start\n",
      "                            if in_project:\n",
      "                                parse_start = time.time()\n",
      "                                ts = dateutil.parser.parse(timestamp)\n",
      "                                ts = datetime.datetime.fromtimestamp(calendar.timegm(ts.timetuple()))\n",
      "                                if contributor_id == '':\n",
      "                                    contributor_id = 0\n",
      "                                if minor == '1':\n",
      "                                    minor = True\n",
      "                                else:\n",
      "                                    minor = False\n",
      "                                time_parse += time.time() - parse_start\n",
      "                                orm_start = time.time()\n",
      "                                to_insert.append(\n",
      "                                    project_table(\n",
      "                                        article_name = article_name\n",
      "                                         , article_id = -1\n",
      "                                         , redirect = redirect\n",
      "                                         , revision_num = revision_num\n",
      "                                         , revision_id = revision_id\n",
      "                                         , timestamp = ts\n",
      "                                         , contributor_id = contributor_id\n",
      "                                         , minor = minor\n",
      "                                         , comment = comment\n",
      "                                         , diff_bytes = bytes_diff\n",
      "                                    )\n",
      "                                )\n",
      "                                orm_time += time.time() - orm_start\n",
      "                        if len(to_insert) >= batch_size:\n",
      "                            #print \"Commiting %d rows\" % len(to_insert)\n",
      "                            db_start = time.time()\n",
      "                            #session.add_all(to_insert)\n",
      "                            session.commit()\n",
      "                            to_insert = []\n",
      "                            time_db += time.time() - db_start\n",
      "                        io_start = time.time()\n",
      "                    except ValueError:\n",
      "                        output.write(\"Skipped row\\t%d\\t%s\\n\" % (i, sys.exc_info()))\n",
      "                        io_start = time.time()\n",
      "                        continue\n",
      "                except EOFError:\n",
      "                    break\n",
      "            f.close()\n",
      "            output.write(\"Reading complete\\n\")\n",
      "            output.write(\"Commiting %d rows\\n\" % len(to_insert))\n",
      "            # Commit any remaining items in the buffer\n",
      "            db_start = time.time()\n",
      "            #session.add_all(to_insert)\n",
      "            session.commit()\n",
      "            to_insert = []\n",
      "            time_db += time.time() - db_start\n",
      "            sofar = time.time() - start\n",
      "            output.write(\"Rows processed\\t%d\\t%f\\t%f\\n\" % (\n",
      "                row_count, sofar, sofar/float(row_count)))\n",
      "            output.write(\"Performance\\tdb:%f\\tsearch:%f\\tio:%f\\tparse:%f\\torm:%f\\n\" % (\n",
      "                time_db, time_search, time_io, time_parse, time_orm))\n",
      "            # Sleep to allow program to catch KeyboardInterrupt\n",
      "            time.sleep(0.1)\n",
      "    except:\n",
      "        output.write(\"Exception on row\\t%d\\t%s\\n\" % (last, sys.exc_info()))\n",
      "        session.close()\n",
      "        f.close()\n",
      "        raise\n",
      "session.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}