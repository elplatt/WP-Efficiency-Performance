{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import logging\n",
      "import time\n",
      "import sys\n",
      "from IPython.display import clear_output\n",
      "from matplotlib import pyplot as plt\n",
      "import sqlalchemy\n",
      "from sqlalchemy import desc, func\n",
      "from sqlalchemy.orm import sessionmaker"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import database\n",
      "from database.schema import ArticleContributor, contributor_table, revision_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_file = \"data/articles-projects.json\"\n",
      "output_file = \"output/coeditor_%d.tsv\"\n",
      "log_file = \"output/08_create_coeditor.log\"\n",
      "batch_size = 50000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log = logging.getLogger(\"wp-efficiency-performance:load-history\")\n",
      "log.propagate = False\n",
      "log.handlers = []\n",
      "handler = logging.FileHandler(log_file, \"w\")\n",
      "log.addHandler(handler)\n",
      "log.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_ids = []\n",
      "with open(project_file, \"rb\") as f:\n",
      "    for row in f:\n",
      "        data = json.loads(row)\n",
      "        project_ids.append(data[\"project_id\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load project data into articles_contributors\n",
      "def compute_articles_contributors(project_id, log):\n",
      "    start = time.time()\n",
      "    Session = sessionmaker()\n",
      "    Session.configure(bind=database.engine)\n",
      "    session = Session()\n",
      "    try:\n",
      "        revisions = revision_table(project_id)\n",
      "        row_count = 0\n",
      "        to_add = []\n",
      "        log.info(\"Computing articles_contributors for project %d\" % project_id)\n",
      "        for result in session.query(\n",
      "                revisions.contributor_id,\n",
      "                revisions.article_name,\n",
      "                func.min(revisions.timestamp),\n",
      "                func.max(revisions.timestamp)) \\\n",
      "                .group_by(revisions.contributor_id, revisions.article_name) \\\n",
      "                .filter(revisions.contributor_id != 0):\n",
      "            to_add.append(ArticleContributor(\n",
      "                contributor_id=result[0]\n",
      "                , article_name=result[1]\n",
      "                , first_edit=result[2]\n",
      "                , last_edit=result[3]))\n",
      "            row_count += 1\n",
      "            if len(to_add) >= batch_size:\n",
      "                session.add_all(to_add)\n",
      "                session.commit()\n",
      "                to_add = []\n",
      "                log.info(\"%d rows in %f seconds\" % (row_count, time.time() - start))\n",
      "                time.sleep(0.1)\n",
      "        session.add_all(to_add)\n",
      "        session.commit()\n",
      "        to_add = []\n",
      "        log.info(\"%d rows in %f seconds\" % (row_count, time.time() - start))\n",
      "    except:\n",
      "        log.error(sys.exc_info()[1])\n",
      "        raise\n",
      "    finally:\n",
      "        session.close()\n",
      "        log.info(\"Finished computing project %d articles_contributors %d rows in %f seconds\" % (\n",
      "            project_id, row_count, time.time() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create indexes on articles_contributors\n",
      "def index_articles_contributors(project_id, log):\n",
      "    start = time.time()\n",
      "    log.info(\"Indexing articles_contributors\")\n",
      "    sql = \"CREATE INDEX articles_contributors_first ON articles_contributors (first_edit);\"\n",
      "    database.engine.execute(sql)\n",
      "    sql = \"CREATE INDEX articles_contributors_last ON articles_contributors (last_edit);\"\n",
      "    database.engine.execute(sql)\n",
      "    sql = \"CREATE INDEX articles_contributors_name ON articles_contributors (article_name);\"\n",
      "    database.engine.execute(sql)\n",
      "    log.info(\"Finished indexing project %d articles_contributors. %f seconds\" % (\n",
      "            project_id, time.time() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clear articles_contributors\n",
      "def clear_articles_contributors(log):\n",
      "    log.info(\"Removing indexes from articles_contributors\")\n",
      "    sql = \"DROP INDEX articles_contributors_first ON articles_contributors;\"\n",
      "    database.engine.execute(sql)\n",
      "    sql = \"DROP INDEX articles_contributors_last ON articles_contributors;\"\n",
      "    database.engine.execute(sql)\n",
      "    sql = \"DROP INDEX articles_contributors_name ON articles_contributors;\"\n",
      "    database.engine.execute(sql)\n",
      "    log.info(\"Truncating articles_contributors\")\n",
      "    sql = \"TRUNCATE articles_contributors\"\n",
      "    database.engine.execute(sql)\n",
      "    log.info(\"Done clearing articles_contributors\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write articles_contributors as a graph edge TSV\n",
      "def write_articles_contributors_tsv(project_id, log):\n",
      "    start = time.time()\n",
      "    log.info(\"Writing article-editor TSV for project %d\" % project_id)\n",
      "    Session = sessionmaker()\n",
      "    Session.configure(bind=database.engine)\n",
      "    session = Session()\n",
      "    row_count = 0\n",
      "    try:\n",
      "        with open(\"output/%d-article-editor.tsv\" % project_id, \"wb\") as f:\n",
      "            for result in session.query(ArticleContributor):\n",
      "                f.write((u\"%d\\t%s\\n\" % (result.contributor_id, result.article_name)).encode(\"utf-16-le\"))\n",
      "                row_count += 1\n",
      "    finally:\n",
      "        session.close()\n",
      "        log.info(\"Finished writing article-editor TSV for project %d. %d rows in %f seconds\" % (\n",
      "            project_id, row_count, time.time() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create an editor-editor network from articles_contributors\n",
      "def compute_coeditor(project_id, log, batch_size=100000):\n",
      "    log.info(\"Computing coeditor network for project %d\" % project_id)\n",
      "    start = time.time()\n",
      "    Session = sessionmaker()\n",
      "    Session.configure(bind=database.engine)\n",
      "    session = Session()\n",
      "    conn = database.engine.connect()\n",
      "    edges = set()\n",
      "    pair_count = 0\n",
      "    article_count = 0\n",
      "    try:\n",
      "        # Loop through articles\n",
      "        name_q = session.query(ArticleContributor.article_name).distinct()\n",
      "        for i, name_res in enumerate(name_q):\n",
      "            # For each article, get list of first and last edits for all editors\n",
      "            article_name = name_res[0]\n",
      "            log.info(\"  Starting article: %s. Edge queue: %d\" % (article_name, len(edges)))\n",
      "            first_q = session.query(\n",
      "                    ArticleContributor.contributor_id,\n",
      "                    ArticleContributor.first_edit) \\\n",
      "                .filter(ArticleContributor.article_name == article_name) \\\n",
      "                .order_by(ArticleContributor.first_edit)\n",
      "            first_edits = first_q.all()\n",
      "            last_q = session.query(\n",
      "                    ArticleContributor.contributor_id,\n",
      "                    ArticleContributor.last_edit) \\\n",
      "                .filter(ArticleContributor.article_name == article_name) \\\n",
      "                .order_by(desc(ArticleContributor.last_edit))\n",
      "            last_edits = last_q.all()\n",
      "            for first in first_edits:\n",
      "                for last in last_edits:\n",
      "                    if last[1] <= first[1]:\n",
      "                        break\n",
      "                    if first[0] != last[0]:\n",
      "                        edges.add((first[0], last[0]))\n",
      "            pair_count += len(last_edits)\n",
      "            article_count += 1\n",
      "            if i % 10 == 0:\n",
      "                time.sleep(0.1)\n",
      "        log.info(\"  Loading edges into table\");\n",
      "        # Convert set into list\n",
      "        edge_list = list()\n",
      "        while len(edges) > 0:\n",
      "            edge_list.append(edges.pop())\n",
      "        edges = edge_list\n",
      "        # Load edges into contributor_contributor in batches\n",
      "        coeditors = contributor_table(project_id).__table__\n",
      "        while len(edges) > 0:\n",
      "            log.info(\"    Processing next %d of %d\" % (batch_size, len(edges)))\n",
      "            batch = edges[0:batch_size]\n",
      "            batch_data = []\n",
      "            for edge in batch:\n",
      "                batch_data.append({\"source_id\": edge[0], \"target_id\": edge[1]})\n",
      "            conn.execute(coeditors.insert(), batch_data)\n",
      "            edges = edges[batch_size:]\n",
      "    except:\n",
      "        log.error(sys.exc_info()[1])\n",
      "        raise\n",
      "    finally:\n",
      "        session.close()\n",
      "        conn.close()\n",
      "        log.info(\"Finished computing coeditor network for project %d. %d, %d in %f seconds\" % (\n",
      "            project_id, article_count, pair_count, time.time() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create indexes on contributors_contributors\n",
      "def index_coeditor(project_id, log):\n",
      "    start = time.time()\n",
      "    log.info(\"Indexing coeditor table\")\n",
      "    sql = \"CREATE INDEX cc%d_edge ON %d_contributor_contributor (source_id, target_id);\" % (\n",
      "        project_id, project_id)\n",
      "    database.engine.execute(sql)\n",
      "    log.info(\"Done indexing coeditor table for project %d. %f seconds\" % (\n",
      "        project_id, time.time() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for project_id in range(83, 2037):\n",
      "    compute_articles_contributors(project_id, log)\n",
      "    index_articles_contributors(log)\n",
      "    write_articles_contributors_tsv(project_id, log)\n",
      "    compute_coeditor(project_id, log)\n",
      "    index_coeditor(project_id, log)\n",
      "    clear_articles_contributors(log)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write editor-editor graph edge TSV\n",
      "project_id = 1\n",
      "with open(\"output/editor-editor.tsv\", \"wb\") as f:\n",
      "    f.write(u\"Source\\tTarget\\n\".encode(\"utf-16-le\"))\n",
      "    for edge in edges:\n",
      "        f.write((u\"%d\\t%s\\n\" % (edge[0][0], edge[1][0])).encode(\"utf-16-le\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}